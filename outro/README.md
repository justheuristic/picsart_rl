
## RL for deep learning tasks
* [Slides](https://yadi.sk/i/7TkZUDkt3GoPXE)
* Our [lecture](https://yadi.sk/i/-U5w4NpJ3H5TWD), [seminar](https://yadi.sk/i/W3N7-6is3H5TWN)
* The only more-or-less relevant video-lecture we could find in english - [video](https://www.youtube.com/watch?v=2tKNpzUvDc4	)
* Will hopefully record our lecture in english soon!
* Self-critical sequence traning [original article](https://arxiv.org/abs/1612.00563)
* Notebooks - using some of our code & scst solution by A. Pankratov (YSDA)
## Miscellaneous stuff
* An [awesome post](http://distill.pub/2016/augmented-rnns/) explaining attention and long-term memory models.
* [BLEU](http://www.aclweb.org/anthology/P02-1040.pdf) and [CIDEr](https://arxiv.org/pdf/1411.5726.pdf) articles.
* Image captioning
  * MSCOCO captioning [challenge](http://mscoco.org/dataset/#captions-challenge2015)
  * Captioning baseline [notebook](https://github.com/yandexdataschool/HSE_deeplearning/blob/master/week7/captioning_solution_ars.ipynb)
* Other articles on reinforcement learning for natural language: 
  * [task-oriented conversation system](https://arxiv.org/abs/1703.07055)
  * [generating dialogues](https://arxiv.org/abs/1606.01541)
  * [sequential adversarial networks](https://arxiv.org/abs/1609.05473) (a.k.a. SeqGAN)
  * A large overview for machine translation (touching on RL, including RL failures) - [article](https://arxiv.org/abs/1609.08144)
  * How _not_ to evaluate conversation models - [article](https://arxiv.org/abs/1603.08023)
* Overview of other non-games applications ("that article again") - https://arxiv.org/abs/1701.07274


## Reinforcement learning in large/continuous action spaces
While you already know algorithms that will work with continuously many actions, it can't hurt to learn something more specialized.
 * Deterministic policy gradient - [article](https://arxiv.org/pdf/1512.07679.pdf), [post+code](https://yanpanlau.github.io/2016/10/11/Torcs-Keras.html)
 * Stochastic value gradient - [article](https://arxiv.org/abs/1510.09142)
 * Q-learning with normalized advantage functions - [article](https://arxiv.org/abs/1603.00748), [code1](https://github.com/carpedm20/NAF-tensorflow), [code2](http://bit.ly/2qx2087)
 * Embedding large discrete action spaces for RL - [article](https://arxiv.org/pdf/1512.07679.pdf)
 * Lecture by A. Seleznev, 5vision (russian) - [video](www.youtube.com/watch?v=j1L2FnanXPo&t=119m45s)

## Other
* Learning by imitation - [video](https://www.youtube.com/watch?v=kl_G95uKTHw), [assignment](http://rll.berkeley.edu/deeprlcourse/docs/hw1.pdf)(berkeley cs294)
* Knowledge transfer in RL - [video](https://www.youtube.com/watch?v=Hx4XpVdJOI0)(berkeley cs294)
* Inverse reinforcement learning - [video](https://www.youtube.com/watch?v=J2blDuU3X1I)
* Hierarchical reinforcemnt learning - [pending]
* [Your contribution]

## A list of lists
* Our YSDA&HSE RL course that resembles what we did here [practical_rl](https://github.com/yandexdataschool/practical_rl/)
* [awesome_rl](https://github.com/aikorea/awesome-rl/) - a curated list of resources dedicated to reinforcement learning.
* [junhyukoh's list](https://github.com/junhyukoh/deep-reinforcement-learning-papers)
* [muupan's list](https://github.com/muupan/deep-reinforcement-learning-papers)
* Courses:
 * [CS294: deep reinforcement learning](http://rll.berkeley.edu/deeprlcourse/)
 * [Silver's RL course](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html)
 * [Sutton's book, 2nd edition](http://incompleteideas.net/sutton/book/the-book-2nd.html)
* [Implementations of many basic RL algorithms (raw and/or tensorflow)](https://github.com/dennybritz/reinforcement-learning)
* Reddit: [General ML](https://www.reddit.com/r/MachineLearning/), [RL](https://www.reddit.com/r/reinforcementlearning/), [CS294](https://www.reddit.com/r/berkeleydeeprlcourse/)
